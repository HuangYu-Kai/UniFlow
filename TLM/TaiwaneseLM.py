import os
import shutil
import time
import requests
import urllib3
import datetime
from openai import OpenAI
from gradio_client import Client, handle_file

# ==========================================
# 1. è¨­å®šå€
# ==========================================

# âš ï¸ è«‹å¡«å…¥æ‚¨çš„ NVIDIA API Key
NVIDIA_API_KEY = "-----" 

# TTS æœå‹™ç¶²å€èˆ‡å‚™ç”¨æª”æ¡ˆ
TTS_APP_URL = "https://tts.ivoice.tw:5003/"
FALLBACK_AUDIO_URL = "https://tts.ivoice.tw:5003/gradio_api/file=/home/tianyi/tts_taigi/gradio_cache/169345990328661d3035ba3c7e69d5ffb04bb34947acf44c22416982989c8bdc/æ–‡åŒ–ç›¸æ”¾ä¼´_ep080_085_æ¸¬è©¦é›†.wav"
FALLBACK_TEXT = "ai3 tsu3- i3 an1- tsuan5 --ooh4 , a1- kong1 tshue1 tian7- hong1 , lin2 u7 oh8 --khi2- lai5 ah8 bo5 ?"
LOCAL_REF_AUDIO = "reference_audio.wav"

# åˆ†éš”ç¬¦è™Ÿ
SEPARATOR = "###TL###"

# å…¨åŸŸè®Šæ•¸
GLOBAL_CLIENT = None
GLOBAL_REF_AUDIO = None
GLOBAL_REF_TEXT = None

# å¿½ç•¥ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==========================================
# 2. ç³»çµ±åˆå§‹åŒ– (é›™é‡ä¿éšªæ©Ÿåˆ¶)
# ==========================================

def download_fallback_file():
    """ å¼·åˆ¶ä¸‹è¼‰å®˜æ–¹éŸ³æª”åˆ°æœ¬åœ° """
    if os.path.exists(LOCAL_REF_AUDIO):
        return True
    print("ğŸ“¥ æ­£åœ¨ä¸‹è¼‰å‚™ç”¨åƒè€ƒéŸ³æª”...")
    try:
        response = requests.get(FALLBACK_AUDIO_URL, verify=False, timeout=30)
        with open(LOCAL_REF_AUDIO, 'wb') as f:
            f.write(response.content)
        return True
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
        return False

def init_tts_system():
    global GLOBAL_CLIENT, GLOBAL_REF_AUDIO, GLOBAL_REF_TEXT
    
    # 1. å…ˆæŠŠå‚™ç”¨æª”æ¡ˆæº–å‚™å¥½ (ä¿å‘½ç¬¦)
    download_fallback_file()
    
    print("âš™ï¸ æ­£åœ¨é€£ç·š TTS ç³»çµ±...")
    try:
        GLOBAL_CLIENT = Client(TTS_APP_URL, ssl_verify=False)
        
        # 2. å˜—è©¦å‹•æ…‹åˆ‡æ›æ¨¡å‹
        try:
            result = GLOBAL_CLIENT.predict(
                model_path="pretrained_For_Selection/å°èªæ¨¡å‹",
                api_name="/change_model"
            )
            # å˜—è©¦æŠ“å–ä¼ºæœå™¨å›å‚³çš„éŸ³æª”
            raw_audio = result[2]
            if isinstance(raw_audio, dict):
                server_audio = raw_audio.get('path') or raw_audio.get('url')
            else:
                server_audio = raw_audio
            
            # 3. åˆ¤æ–·ï¼šå¦‚æœä¼ºæœå™¨çµ¦çš„æª”æ¡ˆæœ‰æ•ˆï¼Œå°±ç”¨ä¼ºæœå™¨çš„ï¼›å¦å‰‡ç”¨æœ¬åœ°å‚™ä»½
            if server_audio:
                GLOBAL_REF_AUDIO = server_audio
                print("âœ… ä½¿ç”¨ä¼ºæœå™¨æä¾›çš„åƒè€ƒéŸ³æª”")
            else:
                raise ValueError("ä¼ºæœå™¨å›å‚³ç©ºå€¼")
                
            GLOBAL_REF_TEXT = result[3]

        except Exception as e:
            print(f"âš ï¸ å‹•æ…‹å–å¾—åƒè€ƒéŸ³æª”å¤±æ•— ({e})ï¼Œåˆ‡æ›è‡³æœ¬åœ°å‚™ç”¨æ–¹æ¡ˆ...")
            # === å‚™ç”¨æ–¹æ¡ˆå•Ÿå‹• ===
            GLOBAL_REF_AUDIO = LOCAL_REF_AUDIO
            GLOBAL_REF_TEXT = FALLBACK_TEXT
            print(f"âœ… å·²åˆ‡æ›ä½¿ç”¨æœ¬åœ°éŸ³æª”: {LOCAL_REF_AUDIO}")

        return True

    except Exception as e:
        print(f"âŒ TTS ç³»çµ±é€£ç·šå¾¹åº•å¤±æ•—: {e}")
        return False

# ==========================================
# 3. èªéŸ³åˆæˆ
# ==========================================

def speak_taigi_pinyin(romanized_text):
    if not romanized_text or not romanized_text.strip(): return
    romanized_text = romanized_text.replace("\n", " ").strip()

    # å†æ¬¡æª¢æŸ¥éŸ³æª”æ˜¯å¦å­˜åœ¨
    final_ref_audio = GLOBAL_REF_AUDIO
    # å¦‚æœæ˜¯ç”¨æœ¬åœ°æª”æ¡ˆï¼Œè¦ç¢ºä¿è·¯å¾‘æ­£ç¢ºå‚³å…¥
    if final_ref_audio == LOCAL_REF_AUDIO:
        if not os.path.exists(LOCAL_REF_AUDIO):
            print("âŒ æ‰¾ä¸åˆ°æœ¬åœ°åƒè€ƒéŸ³æª”ï¼Œç„¡æ³•ç™¼éŸ³")
            return
    
    if not GLOBAL_CLIENT:
        print("âš ï¸ TTS Client æœªé€£ç·š")
        return

    try:
        timestamp = datetime.datetime.now().strftime("%H%M%S%f")
        final_filename = f"response_{timestamp}.wav"

        # print(f"[DEBUG] ç™¼éŸ³å…§å®¹: {romanized_text}")
        
        result_path = GLOBAL_CLIENT.predict(
            tts_text=romanized_text,
            mode_checkbox_group="3sæ¥µé€Ÿè¦†åˆ»",
            prompt_text=GLOBAL_REF_TEXT,
            # é€™è£¡ handle_file æœƒè‡ªå‹•è™•ç†ç¶²å€æˆ–æœ¬åœ°è·¯å¾‘
            prompt_wav_upload=handle_file(final_ref_audio), 
            prompt_wav_record=None,
            instruct_text="Speak very slowly",
            seed=0,
            speed=1.0,
            enable_translation=False, # é—œé–‰ç¿»è­¯ï¼Œå”¸æ‹¼éŸ³
            api_name="/generate"
        )

        if isinstance(result_path, dict):
            result_path = result_path.get('path') or result_path.get('url')

        if result_path and os.path.exists(result_path):
            shutil.copy(result_path, final_filename)
            os.startfile(final_filename)
            time.sleep(0.2)
        else:
            print("âŒ TTS åˆæˆç„¡æª”æ¡ˆ")

    except Exception as e:
        print(f"âŒ ç™¼éŸ³éŒ¯èª¤: {e}")

# ==========================================
# 4. ä¸»ç¨‹å¼
# ==========================================

def main():
    client = OpenAI(
        base_url = "https://integrate.api.nvidia.com/v1",
        api_key = NVIDIA_API_KEY
    )

    system_prompt = f"""
    ä½ æ˜¯ä¸€å€‹ç²¾é€šã€Œè‡ºç£é–©å—èªï¼ˆå°èªï¼‰ã€çš„ AI åŠ©ç†ã€‚
    
    ã€è¦å‰‡ã€‘
    1. å‰åŠæ®µï¼šè«‹ç”¨ã€Œç¹é«”è¯èªã€å›ç­”ï¼Œä¸è¦å‡ºç¾æ‹¼éŸ³ã€‚
    2. åˆ†éš”ç¬¦ï¼šå›ç­”çµæŸå¾Œï¼Œå¿…é ˆæ›è¡Œä¸¦åŠ ä¸Š "{SEPARATOR}"ï¼Œå†æ›è¡Œã€‚
    3. å¾ŒåŠæ®µï¼šå°‡å‰åŠæ®µç¿»è­¯æˆã€Œè‡ºç¾…æ‹¼éŸ³ (TÃ¢i-lÃ´)ã€ã€‚
       - åªè¦çµ¦æ‹¼éŸ³å°±å¥½ï¼Œä¸è¦åŠ ä»»ä½•è§£é‡‹æ–‡å­—ã€‚
       - è²èª¿ç”¨æ•¸å­— (1-8)ã€‚
    
    ç¯„ä¾‹ï¼š
    ä½ å¥½ï¼Œå¾ˆé«˜èˆˆèªè­˜ä½ ã€‚
    {SEPARATOR}
    Li2 ho2, tsin1 huan-hi2 jin7-bat4 li2.
    """

    conversation_history = [{"role": "system", "content": system_prompt}]

    print("=== å°èª AI èŠå¤©å®¤ (Hybrid Final) ===")
    
    if init_tts_system():
        print("âœ… èªéŸ³ç³»çµ±å°±ç·’ï¼\n")
    else:
        print("âš ï¸ èªéŸ³ç³»çµ±æ•…éšœã€‚\n")

    while True:
        try:
            user_input = input("\nä½ ï¼š")
            if user_input.lower() in ["exit", "quit", "é›¢é–‹"]:
                speak_taigi_pinyin("To-sia7, tsai3-hue7!")
                time.sleep(3)
                break
            
            conversation_history.append({"role": "user", "content": user_input})

            completion = client.chat.completions.create(
                model="yentinglin/llama-3-taiwan-70b-instruct",
                messages=conversation_history,
                temperature=0.3, # æº«åº¦èª¿ä½ï¼Œæ ¼å¼è¼ƒç©©
                top_p=1,
                max_tokens=1024,
                stream=True
            )

            print("AIï¼š", end="")
            full_response = ""
            is_printing = True

            for chunk in completion:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    
                    if is_printing:
                        if SEPARATOR not in full_response:
                            print(content, end="", flush=True)
                        else:
                            if SEPARATOR in content:
                                print(content.split(SEPARATOR)[0], end="", flush=True)
                            is_printing = False

            print()

            conversation_history.append({"role": "assistant", "content": full_response})
            
            if SEPARATOR in full_response:
                # ä½¿ç”¨ splitï¼Œä¸¦ç¢ºä¿æœ‰å–åˆ°å¾ŒåŠæ®µ
                parts = full_response.split(SEPARATOR)
                if len(parts) > 1:
                    pinyin_part = parts[1].strip()
                    speak_taigi_pinyin(pinyin_part)
                else:
                    print("(AI æœªç”¢ç”Ÿå®Œæ•´æ‹¼éŸ³)")
            else:
                pass 
                # print("(æœªåµæ¸¬åˆ°åˆ†éš”ç¬¦è™Ÿ)")
        
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"éŒ¯èª¤: {e}")

if __name__ == "__main__":
    main()